{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from utils import *\n",
    "from dataset import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_path = 'checkpoints/same_epoch_25.pth'#'checkpoints/epoch_45.pth'\n",
    "epochs = 100\n",
    "lr = .002\n",
    "padding = 'same'\n",
    "data_path = '/data/Cityscapes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Detected 1 GPU. Loading model onto single GPU.\n",
      ">> Loading pretrained weights from: checkpoints/same_epoch_25.pth\n",
      "take 2 worked\n"
     ]
    }
   ],
   "source": [
    "model = UNET(n_classes=34, padding=padding)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = pixelwise_loss  # wrapper for nn.CrossEntropyLoss()\n",
    "\n",
    "# Load model onto available GPUs\n",
    "if torch.cuda.is_available():\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\">> Detected {} GPUs! Training's about to get hella fast\".format(torch.cuda.device_count()))\n",
    "        model = nn.DataParallel(model)\n",
    "        \n",
    "    else:\n",
    "        print('>> Detected {} GPU. Loading model onto single GPU.'.format(torch.cuda.device_count()))\n",
    "    batch_size = torch.cuda.device_count() # To make sure all GPUs are utilized\n",
    "    model.cuda()\n",
    "else:\n",
    "    batch_size = 1\n",
    "    print('>> No GPU detected - training on cpu.')\n",
    "\n",
    "# Load pretrained weights\n",
    "if pretrained_path is not None:\n",
    "    print('>> Loading pretrained weights from: {}'.format(pretrained_path))\n",
    "    checkpoint = torch.load(pretrained_path)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.cuda()\n",
    "else:\n",
    "    print('>> Initializing new model.')\n",
    "    start_epoch = 0\n",
    "\n",
    "# Load datasets\n",
    "cityscapes_train = Cityscapes(root=data_path)\n",
    "cityscapes_val = Cityscapes(root=data_path, split='val')\n",
    "cityscapes_test = Cityscapes(root=data_path, split='test')\n",
    "train_loader = DataLoader(cityscapes_train, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "val_loader = DataLoader(cityscapes_val, batch_size=batch_size, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all weights are loaded onto cuda\n",
    "for param in model.parameters():\n",
    "    if param.device == 'cpu':\n",
    "        print('Found device {} on cpu!'.format(device.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "dataset = cityscapes_val\n",
    "i = np.random.randint(low=0, high=len(dataset)-1)\n",
    "\n",
    "print(\"Plotting image {} from the '{}' dataset.\".format(i, dataset.split))\n",
    "plot_cityscape(i, dataset=dataset, class_ids=dataset.class_ids)\n",
    "# Image 377 from 'val' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run validation set before training the model \n",
    "num_classes = model.module.n_classes if type(model) == nn.DataParallel else model.n_classes\n",
    "with torch.no_grad():\n",
    "    val_acc, val_iou, val_loss = run_model(model, val_loader, criterion, mode='val')\n",
    "print('Before training: val_loss: {:.3f}. val_acc: {:.3f}. val_iou: {:.4f}.'.format(\n",
    "    val_loss, \n",
    "    val_acc,\n",
    "    np.nanmean(val_iou)))\n",
    "\n",
    "if pretrained_path is not None:\n",
    "    history = checkpoint['history']\n",
    "else:\n",
    "    history = {'val_loss': [val_loss],\n",
    "           'val_acc': [val_acc],\n",
    "          'val_iou': val_iou.reshape((1, -1)),\n",
    "          'train_loss': [np.nan],\n",
    "           'train_acc': [np.nan],\n",
    "          'train_iou': np.full(shape=(1, num_classes), fill_value=np.nan)}\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # adjust learning rate\n",
    "    new_lr = lr / 2**int(epoch//10)\n",
    "    adjust_learning_rate(new_lr, optimizer)\n",
    "    \n",
    "    # train\n",
    "    train_acc, train_iou, train_loss = train(model, train_loader, criterion, optimizer)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_iou'] = np.concatenate((history['train_iou'], train_iou.reshape(1, -1)), axis=0)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    \n",
    "    # validate\n",
    "    val_acc, val_iou, val_loss = validate(model, val_loader, criterion)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_iou'] = np.concatenate((history['val_iou'], val_iou.reshape(1, -1)), axis=0)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    \n",
    "    # summary\n",
    "    time_since_start = time.time() - start_time\n",
    "    avg_time_per_epoch = time_since_start/(epoch+1)\n",
    "    time_remaining = epochs*avg_time_per_epoch - time_since_start\n",
    "    print('Completed epoch {}/{}. val_loss: {:.3f}. val_acc: {:.3f}. val_iou: {:.4f}. ETA: {:.1f} mins remaining.'.format(\n",
    "        epoch+1, \n",
    "        epochs, \n",
    "        val_loss, \n",
    "        val_acc,\n",
    "        np.nanmean(val_iou),\n",
    "        time_remaining/60))\n",
    "    \n",
    "    # Save model every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        if not os.path.exists('checkpoints/'):\n",
    "            os.mkdir('checkpoints/')\n",
    "        filename = 'checkpoints/epoch_'+str(epoch+1)+'.pth'\n",
    "        print('Saving checkpoint to: {}'.format(filename))\n",
    "        state = {'epoch': epoch + 1, \n",
    "                 'state_dict': model.state_dict(),\n",
    "                 'optimizer' : optimizer.state_dict(),\n",
    "                 'history': history}\n",
    "        torch.save(state, filename)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
