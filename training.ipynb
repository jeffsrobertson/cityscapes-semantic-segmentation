{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from utils import *\n",
    "from dataset import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU detected - training on cpu.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found or incomplete. Please make sure all required folders for the specified \"split\" and \"mode\" are inside the \"root\" directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f465115ecd47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No GPU detected - training on cpu.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcityscapes_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCityscapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/data/Cityscapes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mcityscapes_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCityscapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/data/Cityscapes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mcityscapes_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCityscapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/data/Cityscapes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cityscapes-unet/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, split, mode)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mCityscapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCityscapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fine'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'semantic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         self.class_ids = {0: 'unlabeled',\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torchvision/datasets/cityscapes.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, split, mode, target_type, transform, target_transform, transforms)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mextract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_dir_zip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                 raise RuntimeError('Dataset not found or incomplete. Please make sure all required folders for the'\n\u001b[0m\u001b[1;32m    145\u001b[0m                                    ' specified \"split\" and \"mode\" are inside the \"root\" directory')\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dataset not found or incomplete. Please make sure all required folders for the specified \"split\" and \"mode\" are inside the \"root\" directory"
     ]
    }
   ],
   "source": [
    "model = UNET(n_classes=34, padding='valid')\n",
    "if torch.cuda.is_available():\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Detected {} GPUs! Training's about to get hella fast\".format(torch.cuda.device_count()))\n",
    "        model = nn.DataParallel(model)\n",
    "        \n",
    "    else:\n",
    "        print('Detected {} GPU. Loading model onto single GPU.'.format(torch.cuda.device_count()))\n",
    "    batch_size = torch.cuda.device_count() # To make sure all GPUs are utilized\n",
    "    model.cuda()\n",
    "else:\n",
    "    batch_size = 1\n",
    "    print('No GPU detected - training on cpu.')\n",
    "    \n",
    "cityscapes_train = Cityscapes(root='/data/Cityscapes')\n",
    "cityscapes_val = Cityscapes(root='/data/Cityscapes', split='val')\n",
    "cityscapes_test = Cityscapes(root='/data/Cityscapes', split='test')\n",
    "\n",
    "train_loader = DataLoader(cityscapes_train, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True)\n",
    "val_loader = DataLoader(cityscapes_val, batch_size=batch_size, num_workers=16, pin_memory=True)\n",
    "\n",
    "epochs = 100\n",
    "criterion = pixelwise_loss  # wrapper for nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "dataset = cityscapes_val\n",
    "i = np.random.randint(low=0, high=len(dataset)-1)\n",
    "\n",
    "print(\"Plotting image {} from the '{}' dataset.\".format(i, dataset.split))\n",
    "plot_cityscape(i, dataset=dataset, class_ids=dataset.class_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run validation set before training the model \n",
    "with torch.no_grad():\n",
    "    val_acc, val_iou, val_loss = run_model(model, val_loader, criterion, mode='val')\n",
    "history = {'val_loss': [val_loss],\n",
    "           'val_acc': [val_acc],\n",
    "          'val_iou': val_iou.reshape((1, -1)),\n",
    "          'train_loss': [np.nan],\n",
    "           'train_acc': [np.nan],\n",
    "          'train_iou': np.full(shape=(1, num_classes), fill_value=np.nan)}\n",
    "print('Before training: val_loss: {:.3f}. val_acc: {:.3f}. val_iou: {:.4f}.'.format(\n",
    "    val_loss, \n",
    "    val_acc,\n",
    "    np.nanmean(val_iou)))\n",
    "    \n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # train\n",
    "    epoch_start = time.time()\n",
    "    train_acc, train_iou, train_loss = run_model(model, train_loader, criterion, optimizer)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_iou'] = np.concatenate((history['train_iou'], train_iou.reshape(1, -1)), axis=0)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    \n",
    "    # validate\n",
    "    with torch.no_grad():\n",
    "        val_acc, val_iou, val_loss = run_model(model, val_loader, criterion, mode='val')\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_iou'] = np.concatenate((history['val_iou'], val_iou.reshape(1, -1)), axis=0)\n",
    "        history['val_loss'].append(val_loss)\n",
    "    \n",
    "    # summary\n",
    "    time_since_start = time.time() - start_time\n",
    "    avg_time_per_epoch = time_since_start/(epoch+1)\n",
    "    time_remaining = epochs*avg_time_per_epoch - time_since_start\n",
    "    print('Completed epoch {}/{}. val_loss: {:.3f}. val_acc: {:.3f}. val_iou: {:.4f}. ETA: {:.1f} mins remaining.'.format(\n",
    "        epoch+1, \n",
    "        epochs, \n",
    "        val_loss, \n",
    "        val_acc,\n",
    "        np.nanmean(val_iou),\n",
    "        time_remaining/60))\n",
    "    \n",
    "    # Save model every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        if not os.path.exists('checkpoints/'):\n",
    "            os.mkdir('checkpoints/')\n",
    "        filename = 'checkpoints/epoch_'+str(epoch+1)+'.pth'\n",
    "        print('Saving checkpoint to: {}'.format(filename))\n",
    "        state = {'epoch': epoch + 1, \n",
    "                 'state_dict': model.state_dict(),\n",
    "                 'optimizer' : optimizer.state_dict(),\n",
    "                 'history': history}\n",
    "        torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# Plot loss vs epochs\n",
    "plt.figure(1)\n",
    "plt.plot(history['val_loss'], label='Validation')\n",
    "plt.plot(history['train_loss'], label='Training')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('# epochs', fontsize=15)\n",
    "plt.title('Loss', fontsize=18)\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(history['val_acc'], label='Validation')\n",
    "plt.plot(history['train_acc'], label='Training')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('# epochs', fontsize=15)\n",
    "plt.title('Total accuracy', fontsize=18)\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "plt.figure(3)\n",
    "for i in range(history['val_iou'].shape[1]):\n",
    "    plt.plot(history['val_iou'][:, i], label=cityscapes_val.class_ids[i])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.ylim([0, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
