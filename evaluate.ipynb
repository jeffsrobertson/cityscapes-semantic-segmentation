{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataset import *\n",
    "from model import *\n",
    "from utils import *\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "take 2 worked\n"
     ]
    }
   ],
   "source": [
    "data_path = '/data/Cityscapes'\n",
    "save_path = 'checkpoints/same_epoch_45.pth'\n",
    "\n",
    "padding = 'same' if save_path.split(sep='/')[1].startswith('same') else 'valid'\n",
    "dataset = Cityscapes(root=data_path, split='val')\n",
    "model = UNET(n_classes=34, padding=padding)\n",
    "\n",
    "save_state = torch.load(save_path)\n",
    "weights = save_state['state_dict']\n",
    "history = save_state['history']\n",
    "\n",
    "model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "i = np.random.randint(low=0, high=len(dataset)-1)\n",
    "\n",
    "print(\"Plotting image {} from the '{}' dataset.\".format(i, dataset.split))\n",
    "test(i, dataset=dataset, model=model)\n",
    "plt.savefig('fig.pdf')\n",
    "# Image 377 from 'val' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.figure(1, figsize=(8, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='training set')\n",
    "plt.plot(history['val_loss'], label='validation set')\n",
    "plt.legend(prop={'size':12})\n",
    "plt.grid()\n",
    "plt.title('Loss', fontsize=20)\n",
    "plt.xlabel('# epochs', fontsize=15)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_acc'], label='training set')\n",
    "plt.plot(history['val_acc'], label='validation set')\n",
    "plt.legend(prop={'size':12})\n",
    "plt.grid()\n",
    "plt.title('Accuracy', fontsize=20)\n",
    "plt.xlabel('# epochs', fontsize=15)\n",
    "plt.ylim([0, 1])\n",
    "plt.tight_layout()\n",
    "#plt.savefig('metrics.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "class_ids = dataset.class_ids\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, sharex=True, sharey=True)\n",
    "\n",
    "for i in [7, 8, 10, 11, 12]:\n",
    "    ax1.plot(history['val_iou'][:, i], label=class_ids[i])\n",
    "ax1.legend(prop={'size': 8}, loc='right')\n",
    "ax1.grid()\n",
    "ax1.set_title('Surfaces')\n",
    "\n",
    "for i in [26, 27, 28, 29, 30, 31, 32]:\n",
    "    ax2.plot(history['val_iou'][:, i], label=class_ids[i])\n",
    "ax2.legend(prop={'size':8}, loc='right')\n",
    "ax2.grid()\n",
    "ax2.set_title('Vehicles')\n",
    "ax2.set_ylim([-.01, 1.])\n",
    "\n",
    "for i in [21, 22, 23, 24, 33]:\n",
    "    ax3.plot(history['val_iou'][:, i], label=class_ids[i])\n",
    "ax3.legend(prop={'size':8}, loc='upper right')\n",
    "ax3.grid()\n",
    "ax3.set_title('Nature / People')\n",
    "ax3.set_ylim([-.01, 1.])\n",
    "ax3.set_xlabel('# epochs')\n",
    "\n",
    "for i in [19, 20, 17, 13]:\n",
    "    ax4.plot(history['val_iou'][:, i], label=class_ids[i])\n",
    "ax4.legend(prop={'size':8})\n",
    "ax4.grid()\n",
    "ax4.set_title('Traffic / Obstacles')\n",
    "ax4.set_ylim([-.01, 1.])\n",
    "ax4.set_xlabel('# epochs')\n",
    "\n",
    "plt.subplots_adjust(wspace=.05)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('classious.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_same = model\n",
    "history_same = history\n",
    "\n",
    "save_path = 'checkpoints/epoch_45.pth'\n",
    "\n",
    "padding = 'same' if save_path.split(sep='/')[1].startswith('same') else 'valid'\n",
    "dataset = Cityscapes(root=data_path, split='val')\n",
    "model = UNET(n_classes=34, padding=padding)\n",
    "\n",
    "save_state = torch.load(save_path)\n",
    "weights = save_state['state_dict']\n",
    "history = save_state['history']\n",
    "try:\n",
    "    print('>> Loading model weights from: {}'.format(save_path))\n",
    "    model.load_state_dict(weights)\n",
    "except:\n",
    "    # If the model was trained on parallel GPUs, it needs this jenky workaround to load it onto CPU\n",
    "    print('>> Model was trained on parallel GPUs. Loading weights onto CPU for evaluation.')\n",
    "    new_weights = OrderedDict()\n",
    "    for k, v in weights.items():\n",
    "        name = k[7:]\n",
    "        new_weights[name] = v\n",
    "    model.load_state_dict(new_weights)\n",
    "    \n",
    "model_valid = model\n",
    "history_valid = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(history_same['val_acc'], label=\"'same' padding\")\n",
    "plt.plot(history_valid['val_acc'], label=\"'valid' padding\", linestyle='dashed')\n",
    "plt.legend(prop={'size':16})\n",
    "plt.grid()\n",
    "plt.ylim([0, 1.])\n",
    "plt.title('Accuracy', fontsize=18)\n",
    "plt.xlabel('# epochs', fontsize=18)\n",
    "plt.savefig('padding.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
